{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a102d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyserini.search as pys\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f11079b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\marij/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\marij/.cache\\huggingface\\transformers\\0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\marij/.cache\\huggingface\\transformers\\75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\marij/.cache\\huggingface\\transformers\\8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\marij/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\marij/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\marij/.cache\\huggingface\\transformers\\9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "searcher = pys.SimpleSearcher('indexes/sample_collection_jsonl')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model     = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dc07a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDoc(id, mode=\"chunk\"):\n",
    "    if(mode == \"linear\"):\n",
    "        res = \"\"\n",
    "        f = open(\"data/collection.tsv\",  encoding=\"utf8\")\n",
    "        for i in range(id+1):\n",
    "            l = f.readline()\n",
    "        return l.strip().split('\\t')\n",
    "    elif(mode == \"chunk\"):\n",
    "        res = id%10000\n",
    "        nearest_n = id - res\n",
    "        f = open(f\"data/collection_chunks/{nearest_n}.txt\",  encoding=\"utf8\")\n",
    "        l = None\n",
    "        if res == 0:\n",
    "            f = open(f\"data/collection_chunks/{id-10000}.txt\",  encoding=\"utf8\")\n",
    "            lines = f.readlines()\n",
    "            l = lines[len(lines)-1]\n",
    "        \n",
    "        for i in range(res):\n",
    "            l = f.readline()\n",
    "        \n",
    "        if l == None:\n",
    "            print(f\"Document not found/read, id: {id}, res id: {res}\")\n",
    "            \n",
    "        return l\n",
    "    \n",
    "def loadQueries(filename = \"data/queries/queries.train.tsv\"):\n",
    "    f = open(filename,  encoding=\"utf8\")\n",
    "    lines = f.readlines()\n",
    "    print(lines[0])\n",
    "    f.close()\n",
    "    return {int(l.strip().split('\\t')[0]):l.strip().split('\\t')[1] for l in lines}\n",
    "    \n",
    "def findQuery(id, cached=True):\n",
    "    if(cached):\n",
    "        content = queries[id]\n",
    "        return [id, content]\n",
    "    t = time.time()\n",
    "    f = open(\"data/queries/queries.train.tsv\",  encoding=\"utf8\")\n",
    "    while True:\n",
    "        l = f.readline().strip().split('\\t')\n",
    "        l[0] = int(l[0])\n",
    "        if(l[0] == id):\n",
    "            print(time.time() - t)\n",
    "            return l\n",
    "        if not l:\n",
    "            break\n",
    "    print(time.time() - t)\n",
    "    return l  \n",
    "\n",
    "def getTrip(f):\n",
    "    l = f.readline().strip().split('\\t')\n",
    "    if l[0] == '':\n",
    "        return None\n",
    "    l = [int(x) for x in l]\n",
    "    l[0] = findQuery(l[0])\n",
    "    l[1] = findDoc(l[1]).strip().split('\\t')\n",
    "    l[2] = findDoc(l[2]).strip().split('\\t')\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = loadQueries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePosSamples():\n",
    "    triples = open(\"data/qidpidtriples.train.full.2.tsv\")\n",
    "    fw = open(\"data/train.pos.txt\", \"w\")\n",
    "    currQ = \"\"\n",
    "    currPos = \"\"\n",
    "    for i in range(4000000):\n",
    "        l = triples.readline()\n",
    "        triple = l.strip().split(\"\\t\")\n",
    "        if(currQ != triple[0] or currPos != triple[1]):\n",
    "            currQ = triple[0]\n",
    "            currPos = triple[1]\n",
    "            fw.write(l)\n",
    "    triples.close()\n",
    "    fw.close()\n",
    "\n",
    "\n",
    "def trainBert():\n",
    "    triples = open(\"data/train.pos.txt\")\n",
    "    \n",
    "    trainingData = []\n",
    "    \n",
    "    for i in range(4000):\n",
    "        triple = getTrip(triples)\n",
    "        if(triple == None):\n",
    "            break\n",
    "        trainingData.append({\"s1\": triple[0][1], \"s2\": triple[1][1]})\n",
    "        if(i%100 == 0):\n",
    "            print(i)\n",
    "        \n",
    "    triples.close()\n",
    "    print(\"What took so long?\")\n",
    "    return trainingData \n",
    "        \n",
    "trainingData = trainBert()\n",
    "# savePosSamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(sample):\n",
    "    return tokenizer(sample[\"s1\"], sample[\"s2\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokens = list(map(tokenize_function, trainingData))\n",
    "\n",
    "tval = 0.8\n",
    "trainsize = int(len(trainingData)*tval)\n",
    "train_tokens = tokens[:trainsize]\n",
    "val_tokens = tokens[trainsize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d20d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "    do_train=True,\n",
    "    do_eval=False,\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     eval_steps=1000,\n",
    "#     logging_dir=\"exp/bart/logs\",\n",
    "#     num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=32,\n",
    "#     gradient_accumulation_steps=2,\n",
    "    eval_accumulation_steps=1,)\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokens,\n",
    "    eval_dataset=val_tokens,\n",
    "    compute_metrics=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085aed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1330a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1000000, 'content': 'where does real insulin come from'}\n"
     ]
    }
   ],
   "source": [
    "# f = open(\"data/queries/queries.dev.tsv\")\n",
    "# f = open(\"data/msmarco-test2019-queries.tsv\")\n",
    "f = open(\"data/hard_queries.txt\")\n",
    "queries = []\n",
    "\n",
    "for i in range(200):\n",
    "    l = f.readline().split(\"\\t\")\n",
    "    if(l[0] != ''):\n",
    "        queries.append({\"id\": int(l[0]), \"content\": l[1].strip()})\n",
    "    \n",
    "print(queries[0])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2503431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for query: where does parrot live\n",
      "7.461893796920776\n",
      "31.696105003356934\n",
      "0.04100227355957031\n",
      "       docid                                           sentence     bm-25  \\\n",
      "792  7264269  Parrots live in just about all of the tropical...  6.799999   \n",
      "\n",
      "         bert     final  rank  bm25-rank  \n",
      "792  0.489199  0.781416   301        306  \n",
      "Checking for query: where does most of the iron ore come from\n",
      "7.417783975601196\n",
      "36.86902379989624\n",
      "0.04298114776611328\n",
      "       docid                                           sentence    bm-25  \\\n",
      "872  7264253  Earth's most important iron ore deposits are f...  10.8964   \n",
      "\n",
      "        bert     final  rank  bm25-rank  \n",
      "872  0.49968  0.844691   112        124  \n",
      "Checking for query: where is weston, fl\n",
      "9.344017744064331\n",
      "37.93731474876404\n",
      "0.04096412658691406\n",
      "       docid         sentence     bm-25      bert     final  rank  bm25-rank\n",
      "894  7942175  Weston, Florida  6.500095  0.506244  0.740717   143        220\n",
      "Checking for query: where does most coal form\n",
      "7.413602828979492\n",
      "34.4340238571167\n",
      "0.03799939155578613\n",
      "       docid                                           sentence   bm-25  \\\n",
      "878  7264249  America is the Saudi Arabia of Coal Plant foss...  7.8827   \n",
      "\n",
      "         bert     final  rank  bm25-rank  \n",
      "878  0.498975  0.796409   108        106  \n"
     ]
    }
   ],
   "source": [
    "def loadHardQrels():\n",
    "    f = open(\"data/hard_qrels.txt\")\n",
    "    lines = [l.strip().split(' ') for l in f.readlines()]\n",
    "    return {int(l[0]): int(l[1]) for l in lines}\n",
    "qrels = loadHardQrels()\n",
    "\n",
    "fw = open(\"bert_hard.txt\", \"w\")\n",
    "resses = []\n",
    "for query in queries[1:]:\n",
    "    if(query[\"id\"] in qrels):\n",
    "        print(f\"Checking for query: {query['content']}\")\n",
    "\n",
    "#         hits = searcher.search(query[\"content\"], k=1000)\n",
    "#         res = []\n",
    "#         for hit in hits:\n",
    "#             res.append(int(hit.docid))\n",
    "#         print(qrels[query[\"id\"]] in res)\n",
    "        \n",
    "        res = bertRankQuery(query[\"content\"], k=1000)\n",
    "        res[\"rank\"] = range(1, len(res)+1)\n",
    "        res = res.sort_values(\"bm-25\", ascending = False)\n",
    "        res[\"bm25-rank\"] = range(1, len(res)+1)\n",
    "        res = res.sort_values(\"final\", ascending = False)\n",
    "        print(res[res[\"docid\"] == qrels[query[\"id\"]]])\n",
    "        exportRes(query, res, fw)\n",
    "        resses.append(res)\n",
    "fw.close()\n",
    "\n",
    "\n",
    "# res[\"rank\"] = range(1, len(res)+1)\n",
    "\n",
    "# print(res[res[\"docid\"] == 7264269])\n",
    "\n",
    "# print(res[res[\"docid\"] == 7264269][\"bert\"]/res[\"bert\"].max())\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d996bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>bm-25</th>\n",
       "      <th>bert</th>\n",
       "      <th>final</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [docid, sentence, bm-25, bert, final, rank]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "289cf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tokenizer will automatically add any model specific separators (i.e. <CLS> and <SEP>) and tokens to\n",
    "# the sequence, as well as compute the attention masks.\n",
    "\n",
    "def getSim(query, doc):\n",
    "    paraphrase = tokenizer(query, doc, return_tensors=\"pt\")\n",
    "    paraphrase_classification_logits = model(**paraphrase).logits\n",
    "    paraphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "    \n",
    "    return paraphrase_results[1]\n",
    "     \n",
    "def calcBertScore(query, doc): \n",
    "    sentences = list(filter(lambda x: x != \"\", [d.strip() for d in doc.split(\".\")]))\n",
    "    \n",
    "    sims = [{\"score\": getSim(query, d), \"sentence\": d} for d in sentences]\n",
    "    sims = sorted(sims, reverse = True, key = lambda x: x[\"score\"])[:3]\n",
    "    n = min(len(sims), 3)\n",
    "    score = 0\n",
    "    for i in range(n):\n",
    "        score = score + w[i]*sims[i][\"score\"]\n",
    "    \n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eea11730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "4.391444444656372\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4028/2942917530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mits\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbertRankQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mexportRes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4028/2942917530.py\u001b[0m in \u001b[0;36mbertRankQuery\u001b[1;34m(query, k)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bert\"\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mcalcBertScores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4028/2942917530.py\u001b[0m in \u001b[0;36mcalcBertScores\u001b[1;34m(query, docs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mencoded_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_of_second_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mclassification_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m         return self.transformer(\n\u001b[0;32m    550\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mposition_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mword_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1916\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def combine3(x):\n",
    "    sims = sorted(x.to_numpy(), reverse=True)\n",
    "    n = min(len(sims), 3)\n",
    "    score = 0\n",
    "    for i in range(n):\n",
    "        score = score + w[i]*sims[i]\n",
    "        \n",
    "    return score\n",
    "\n",
    "def calcBertScores(query, docs): \n",
    "    n = len(docs)\n",
    "    batch_size = 4\n",
    "    n_batches = m.ceil(n/batch_size)\n",
    "    scores = []\n",
    "    for i in range(n_batches):\n",
    "        batch_sentences = [query]*(min((i + 1)*batch_size, n) - i*batch_size)\n",
    "        batch_of_second_sentences = docs[\"sentence\"].to_numpy().tolist()[i*batch_size:min((i + 1)*batch_size, n)]\n",
    "\n",
    "        t =time.time()\n",
    "        \n",
    "        encoded_inputs = tokenizer(batch_sentences, batch_of_second_sentences, padding=True, return_tensors=\"pt\").to(device)\n",
    "        classification_logits = model(**encoded_inputs).logits\n",
    "        results = torch.softmax(classification_logits, dim=1).tolist()\n",
    "        scores = scores + [x[1] for x in results]\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def expandSentences(query, hits):\n",
    "    res_dict = {\"docid\": [], \"sentence\" : [], \"bm-25\": []}\n",
    "    \n",
    "    for hit in hits:\n",
    "        docid = int(hit.docid)\n",
    "        doc = findDoc(docid).split(\"\\t\")[1]\n",
    "        sentences = list(filter(lambda x: x != \"\", [d.strip() for d in doc.split(\".\")]))\n",
    "        for s in sentences:\n",
    "            res_dict[\"docid\"].append(docid)\n",
    "            res_dict[\"sentence\"].append(s)\n",
    "            res_dict[\"bm-25\"].append(hit.score)\n",
    "    \n",
    "    res = pd.DataFrame(res_dict)\n",
    "    return res\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def bertRankQuery(query, k=20):\n",
    "    t = time.time()\n",
    "    hits = searcher.search(query, k=k)\n",
    "    \n",
    "    maxBM = 0\n",
    "    maxBert = 0\n",
    "    \n",
    "    res = expandSentences(query, hits)\n",
    "    print(time.time()-t)\n",
    "    t = time.time()\n",
    "\n",
    "    res[\"bert\"]  = calcBertScores(query, res)\n",
    "    print(time.time()-t)\n",
    "    t = time.time()\n",
    "    agr = res.groupby(\"docid\", as_index=False).first()\n",
    "    agr[\"bert\"] = res.groupby(\"docid\")[\"bert\"].aggregate(combine3).to_numpy()\n",
    "    res = agr\n",
    "    \n",
    "    maxBM = res[\"bm-25\"].max()\n",
    "    maxBert = res[\"bert\"].max()\n",
    "    res[\"final\"] = a*res[\"bm-25\"]/maxBM + (1-a)*res[\"bert\"]/maxBert\n",
    "    res = res.astype({'docid': 'int32'})\n",
    "    res = res.sort_values(\"final\", ascending = False)\n",
    "    print(time.time()-t)\n",
    "    t = time.time()\n",
    "\n",
    "        \n",
    "    return res\n",
    "\n",
    "w = [2/3, 1/6, 1/6]\n",
    "a = 0.5\n",
    "\n",
    "query = queries[0][\"content\"]\n",
    "res = []\n",
    "its = 99\n",
    "\n",
    "fw = open(\"bert_hard.txt\", \"w\")\n",
    "\n",
    "for query in queries:\n",
    "    its = its + 1\n",
    "    print(its)\n",
    "    res = bertRankQuery(query[\"content\"], 500)\n",
    "    print(res)\n",
    "    exportRes(query, res, fw)\n",
    "    print(its)\n",
    "    \n",
    "fw.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f80ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def exportRes(query, res, f):\n",
    "    query = query[\"id\"]\n",
    "    for i in range(len(res)):\n",
    "        docid = res[\"docid\"].iat[i]\n",
    "        score = res[\"final\"].iat[i]\n",
    "        f.write(f\"{query} Q0 {docid} {i + 1} {score} Bertserini \\n\")\n",
    "                \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4308ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"bert\"] = scores\n",
    "    \n",
    "agr = res.groupby(\"docid\").first()\n",
    "agr[\"bert\"] = res.groupby(\"docid\")[\"bert\"].aggregate(combine3)\n",
    "agr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
