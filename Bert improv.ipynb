{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a102d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyserini.search as pys\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f11079b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5fb5a1a40a42709fdb2500c167ad6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b2ef090dd948389cfe7b1d822e3b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4bc4b827144068a052ef8fb387d4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a951a5781ddb45588f926f4a3adad419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f7ef61d7f14308a301a0a0fd1c3a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1048578, 'content': 'cost of endless pools/swim spa'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "searcher = pys.SimpleSearcher('indexes/sample_collection_jsonl')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model     = model.to(device)\n",
    "\n",
    "f = open(\"data/queries.dev.tsv\")\n",
    "queries = []\n",
    "\n",
    "for i in range(20):\n",
    "    l = f.readline().split(\"\\t\")\n",
    "    queries.append({\"id\": int(l[0]), \"content\": l[1].strip()})\n",
    "    \n",
    "print(queries[0])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc3c8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 7471198 21.35000\n",
      " 2 7187236 20.33760\n",
      " 3 5365326 19.68380\n",
      " 4 7187234 19.53490\n",
      " 5 7187242 18.88170\n",
      " 6 2078221 18.84990\n",
      " 7 7187241 18.66050\n",
      " 8 6802210 18.12250\n",
      " 9 6794083 17.85240\n",
      "10 5365328 17.60240\n",
      "11 6750054 17.18490\n",
      "12 4332300 16.23630\n",
      "13 6347088 16.22780\n",
      "14 6347089 16.22780\n",
      "15 6270168 16.07760\n",
      "16 3982208 15.82690\n",
      "17 7471199 15.75350\n",
      "18 7313043 15.45380\n",
      "19 8105762 15.30410\n",
      "20 1139145 15.19000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hits = searcher.search(queries[0]['content'], k=20)\n",
    "\n",
    "\n",
    "for i in range(len(hits)):\n",
    "    print(f'{i+1:2} {hits[i].docid:4} {hits[i].score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc07a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDoc(id, mode=\"chunk\"):\n",
    "    if(mode == \"linear\"):\n",
    "        res = \"\"\n",
    "        f = open(\"data/collection.tsv\",  encoding=\"utf8\")\n",
    "        for i in range(id+1):\n",
    "            l = f.readline()\n",
    "        print(l)\n",
    "    elif mode == \"chunk\":\n",
    "        res = id%10000\n",
    "        nearest_n = id - res\n",
    "        f = open(f\"data/collection_chunks/{nearest_n}.txt\",  encoding=\"utf8\")\n",
    "        for i in range(res):\n",
    "            l = f.readline()\n",
    "        return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "289cf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [2/3, 1/6, 1/6]\n",
    "a = 0.5\n",
    "# The tokenizer will automatically add any model specific separators (i.e. <CLS> and <SEP>) and tokens to\n",
    "# the sequence, as well as compute the attention masks.\n",
    "\n",
    "def getSim(query, doc):\n",
    "    paraphrase = tokenizer(query, doc, return_tensors=\"pt\")\n",
    "    paraphrase_classification_logits = model(**paraphrase).logits\n",
    "    paraphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "    \n",
    "    return paraphrase_results[1]\n",
    "     \n",
    "def calcBertScore(query, doc): \n",
    "    sentences = list(filter(lambda x: x != \"\", [d.strip() for d in doc.split(\".\")]))\n",
    "    \n",
    "    sims = [{\"score\": getSim(query, d), \"sentence\": d} for d in sentences]\n",
    "    sims = sorted(sims, reverse = True, key = lambda x: x[\"score\"])[:3]\n",
    "    n = min(len(sims), 3)\n",
    "    score = 0\n",
    "    for i in range(n):\n",
    "        score = score + w[i]*sims[i][\"score\"]\n",
    "    \n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eea11730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def combine3(x):\n",
    "    sims = sorted(x.to_numpy(), reverse=True)\n",
    "    n = min(len(sims), 3)\n",
    "    score = 0\n",
    "    for i in range(n):\n",
    "        score = score + w[i]*sims[i]\n",
    "        \n",
    "    return score\n",
    "\n",
    "def calcBertScores(query, docs): \n",
    "    n = len(docs)\n",
    "    batch_size = 2\n",
    "    n_batches = m.ceil(n/batch_size)\n",
    "    scores = []\n",
    "    for i in range(n_batches):\n",
    "        batch_sentences = [query]*(min((i + 1)*batch_size, n) - i*batch_size)\n",
    "        batch_of_second_sentences = docs[\"sentence\"].to_numpy().tolist()[i*batch_size:min((i + 1)*batch_size, n)]\n",
    "\n",
    "        t =time.time()\n",
    "        encoded_inputs = tokenizer(batch_sentences, batch_of_second_sentences, padding=True, return_tensors=\"pt\").to(device)\n",
    "        classification_logits = model(**encoded_inputs).logits\n",
    "        results = torch.softmax(classification_logits, dim=1).tolist()\n",
    "        scores = scores + [x[1] for x in results]\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def expandSentences(query, hits):\n",
    "    res_dict = {\"docid\": [], \"sentence\" : [], \"bm-25\": []}\n",
    "    \n",
    "    for hit in hits:\n",
    "        docid = int(hit.docid)\n",
    "        doc = findDoc(docid).split(\"\\t\")[1]\n",
    "        sentences = list(filter(lambda x: x != \"\", [d.strip() for d in doc.split(\".\")]))\n",
    "        for s in sentences:\n",
    "            res_dict[\"docid\"].append(docid)\n",
    "            res_dict[\"sentence\"].append(s)\n",
    "            res_dict[\"bm-25\"].append(hit.score)\n",
    "    \n",
    "    res = pd.DataFrame(res_dict)\n",
    "    return res\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def bertRankQuery(query, k=20):\n",
    "    hits = searcher.search(query, k=k)\n",
    "    \n",
    "    maxBM = 0\n",
    "    maxBert = 0\n",
    "    \n",
    "    res = expandSentences(query, hits)\n",
    "    res[\"bert\"]  = calcBertScores(query, res)\n",
    "    \n",
    "    agr = res.groupby(\"docid\", as_index=False).first()\n",
    "    agr[\"bert\"] = res.groupby(\"docid\")[\"bert\"].aggregate(combine3).to_numpy()\n",
    "    res = agr\n",
    "    \n",
    "    maxBM = res[\"bm-25\"].max()\n",
    "    maxBert = res[\"bert\"].max()\n",
    "    res[\"final\"] = a*res[\"bm-25\"]/maxBM + (1-a)*res[\"bert\"]/maxBert\n",
    "    res = res.astype({'docid': 'int32'})\n",
    "    res = res.sort_values(\"final\", ascending = False)\n",
    "\n",
    "        \n",
    "    return res\n",
    "\n",
    "query = queries[0][\"content\"]\n",
    "res = []\n",
    "\n",
    "for query in queries[:5]:\n",
    "    res.append({\"query\": query, \"res\": bertRankQuery(query[\"content\"], 100)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5f80ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': {'id': 1048578, 'content': 'cost of endless pools/swim spa'}, 'res':       docid                                           sentence      bm-25  \\\n",
      "89  7471198  Cal Spas is the leading maker of home resort p...  21.350000   \n",
      "50  5365326                      How much does a swim spa cost  19.683800   \n",
      "79  7187234  Endless pools and swim spas are available in a...  19.534901   \n",
      "16  2078221  1 A number of value brands will sell swim spas...  18.849899   \n",
      "85  7187242                                   Endless Pools vs  18.881701   \n",
      "..      ...                                                ...        ...   \n",
      "28  3279353  Our customers typically spend about twice the ...  13.975899   \n",
      "58  5800643  He holds licenses for: Construction/ Renovatio...  13.494600   \n",
      "83  7187240  An endless pool, sometimes referred to as a tr...  13.402500   \n",
      "95  8105762  Pinch A Penny Pool Patio & Spa is your headqua...  15.304100   \n",
      "12  1880841  What is a swimming pool autofill? Kona Labs de...  14.427700   \n",
      "\n",
      "        bert     final  \n",
      "89  0.514314  0.998293  \n",
      "50  0.511669  0.956709  \n",
      "79  0.510235  0.951833  \n",
      "16  0.515118  0.940521  \n",
      "85  0.508361  0.934720  \n",
      "..       ...       ...  \n",
      "28  0.413508  0.727931  \n",
      "58  0.421095  0.724010  \n",
      "83  0.415260  0.716200  \n",
      "95  0.333534  0.681554  \n",
      "12  0.328039  0.655706  \n",
      "\n",
      "[100 rows x 5 columns]}, {'query': {'id': 1048579, 'content': 'what is pcnt'}, 'res':       docid                                           sentence      bm-25  \\\n",
      "71  7187227                                    PCNT stands for  11.917500   \n",
      "75  7187232   1 meanings of PCNT acronym and PCNT abbreviation  11.108500   \n",
      "74  7187231  PCNTB, a cDNA homolog of PCNT, was identified ...   9.563200   \n",
      "76  7187233  Data suggest that changes in the expression le...   9.243600   \n",
      "70  7187226                 PCNT deletion/duplication analysis   7.477000   \n",
      "..      ...                                                ...        ...   \n",
      "92  8114700  What is the plural of of decorum? What is the ...   2.598398   \n",
      "77  7210354  What is the past tense of of sirple? What is t...   2.576696   \n",
      "53  6053532  What is the Afrikaans word for hostility? What...   2.588594   \n",
      "79  7494468  What is the Armenian word for Contributed? Wha...   2.580289   \n",
      "0     37604  What is the opposite of devotional? What is th...   2.578200   \n",
      "\n",
      "        bert     final  \n",
      "71  0.521766  0.993656  \n",
      "75  0.513661  0.952045  \n",
      "74  0.522650  0.895717  \n",
      "76  0.510595  0.870902  \n",
      "70  0.528472  0.813698  \n",
      "..       ...       ...  \n",
      "92  0.325221  0.416716  \n",
      "77  0.325759  0.416314  \n",
      "53  0.323811  0.414970  \n",
      "79  0.323046  0.413898  \n",
      "0   0.322420  0.413218  \n",
      "\n",
      "[100 rows x 5 columns]}, {'query': {'id': 1048580, 'content': 'what is pcb waste'}, 'res':       docid                                           sentence      bm-25  \\\n",
      "70  7187206                                                PCB  13.743500   \n",
      "68  7187204  What are the Cleanup and Disposal Options for ...  12.937000   \n",
      "74  7187211  available information on the potential PCBs an...  12.469900   \n",
      "73  7187210                                             รยง 761  12.147700   \n",
      "42  4207128          PCBs are not listed RCRA hazardous wastes  11.911000   \n",
      "..      ...                                                ...        ...   \n",
      "3    676929  What is Hard Drive PCB?Hard Drive PCB is a gre...   9.238700   \n",
      "7   1126206  Waste disposed include TSCA, PCB contaminated ...   9.219000   \n",
      "13  1491211  What is a PCB transformer? Polychlorinated bip...   8.368600   \n",
      "82  7549121  The lower 14 miles of the Sheboygan River and ...   8.144100   \n",
      "93  8338571  Asbestos ( ( ( Asbestos Containing Materials (...   8.144099   \n",
      "\n",
      "        bert     final  \n",
      "70  0.511733  0.984926  \n",
      "68  0.512962  0.956749  \n",
      "74  0.515220  0.941895  \n",
      "73  0.506835  0.922227  \n",
      "42  0.514808  0.921172  \n",
      "..       ...       ...  \n",
      "3   0.341285  0.659518  \n",
      "7   0.332485  0.650462  \n",
      "13  0.338762  0.625473  \n",
      "82  0.332135  0.611025  \n",
      "93  0.322204  0.601614  \n",
      "\n",
      "[100 rows x 5 columns]}, {'query': {'id': 1048581, 'content': 'what is pbis?'}, 'res':       docid                                           sentence     bm-25  \\\n",
      "75  6360936  If you have seen a graphic of the RTI triangle...  9.329900   \n",
      "9    914382  The Expedition Parka is one of Canada Goose's ...  9.247800   \n",
      "32  2733895  PBIS is a research-based, school-wide systems ...  8.902100   \n",
      "45  3210258  PBI is headquartered in Seattle, Washington, a...  8.741500   \n",
      "48  3210263  PBI-blended fabrics have been trusted in the f...  8.537400   \n",
      "..      ...                                                ...       ...   \n",
      "5    397920  Cheap flights from Philadelphia, Pennsylvania ...  6.678300   \n",
      "83  7187806  Pitney Bowes (NYSE: PBI) is a global technolog...  6.199999   \n",
      "35  2733900  Positive Behavior Interventions and Supports (...  6.329500   \n",
      "23  2137804  How Much Does it Cost to Fly from Miami to Wes...  5.927099   \n",
      "24  2137805  When Can I Buy the Cheapest Flight from Miami ...  5.985598   \n",
      "\n",
      "        bert     final  \n",
      "75  0.526406  1.000000  \n",
      "9   0.515705  0.985437  \n",
      "32  0.513631  0.964940  \n",
      "45  0.512926  0.955663  \n",
      "48  0.517564  0.949131  \n",
      "..       ...       ...  \n",
      "5   0.333573  0.674738  \n",
      "83  0.341246  0.656394  \n",
      "35  0.332482  0.655010  \n",
      "23  0.331648  0.632652  \n",
      "24  0.325534  0.629979  \n",
      "\n",
      "[100 rows x 5 columns]}, {'query': {'id': 1048582, 'content': 'what is paysky'}, 'res':       docid                                           sentence      bm-25  \\\n",
      "74  7187186                                         Why PaySky  10.102300   \n",
      "73  7187185                                         Why PaySky  11.014100   \n",
      "72  7187184  You can call it bitelemea or wind technologies...   9.069100   \n",
      "76  7187191                                   PaySky Solutions  10.232999   \n",
      "75  7187188  PaySky Solutions PaySky offers one of the most...  10.233000   \n",
      "..      ...                                                ...        ...   \n",
      "92  8114700  What is the plural of of decorum? What is the ...   2.598398   \n",
      "77  7210354  What is the past tense of of sirple? What is t...   2.576696   \n",
      "56  6053532  What is the Afrikaans word for hostility? What...   2.588594   \n",
      "79  7494468  What is the Armenian word for Contributed? Wha...   2.580289   \n",
      "0     37604  What is the opposite of devotional? What is th...   2.578200   \n",
      "\n",
      "        bert     final  \n",
      "74  0.529696  0.958608  \n",
      "73  0.427427  0.903464  \n",
      "72  0.515819  0.898605  \n",
      "76  0.433575  0.873808  \n",
      "75  0.346904  0.791997  \n",
      "..       ...       ...  \n",
      "92  0.325705  0.425403  \n",
      "77  0.325432  0.424160  \n",
      "56  0.324543  0.423861  \n",
      "79  0.322921  0.421952  \n",
      "0   0.322581  0.421537  \n",
      "\n",
      "[100 rows x 5 columns]}]\n"
     ]
    }
   ],
   "source": [
    "def exportRes(results, filename = \"res.txt\"):\n",
    "    f = open(filename, \"w\")\n",
    "    \n",
    "    for r in results:\n",
    "        res = r[\"res\"]\n",
    "        query = r[\"query\"][\"id\"]\n",
    "        for i in range(len(res)):\n",
    "            docid = res[\"docid\"].iat[i]\n",
    "            score = res[\"final\"].iat[i]\n",
    "            f.write(f\"{query} Q0 {docid} {i + 1} {score} Bertserini \\n\")\n",
    "        \n",
    "exportRes(res)\n",
    "        \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0d4308ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (82) does not match length of index (20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11512/2713204689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bert\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcombine3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3653\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3654\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3655\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3657\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3830\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3831\u001b[0m         \"\"\"\n\u001b[1;32m-> 3832\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3834\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4529\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4530\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ir\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \"\"\"\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    558\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (82) does not match length of index (20)"
     ]
    }
   ],
   "source": [
    "res[\"bert\"] = scores\n",
    "    \n",
    "agr = res.groupby(\"docid\").first()\n",
    "agr[\"bert\"] = res.groupby(\"docid\")[\"bert\"].aggregate(combine3)\n",
    "agr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
